{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T04:40:19.975964Z",
     "start_time": "2021-03-26T04:40:18.172495Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, UpSampling2D, InputLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T04:40:19.980154Z",
     "start_time": "2021-03-26T04:40:19.977622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "# check that TF 2.1.0 is in use\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T04:40:22.151999Z",
     "start_time": "2021-03-26T04:40:21.874682Z"
    }
   },
   "outputs": [],
   "source": [
    "# import dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(data_train, labels_train), (data_test, labels_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T04:40:24.225393Z",
     "start_time": "2021-03-26T04:40:24.220699Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataPrep:\n",
    "# class to prepare the training data by reshaping it, changing the type and normalizing it\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "      \n",
    "    \n",
    "    def dataprep(self):\n",
    "        self.data = self.data.reshape(self.data.shape[0],28,28,1)\n",
    "        self.data = self.data.astype('float32')\n",
    "        self.data /= 255\n",
    "        print('data shape:', self.data.shape)\n",
    "        print('Number of images in data:', self.data.shape[0])\n",
    "        print('max of data:', np.max(self.data), 'min of data:', np.min(self.data))\n",
    "        print('data type:', type(self.data))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T04:40:27.086976Z",
     "start_time": "2021-03-26T04:40:27.084489Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate instances from dataprep class for training data and test data\n",
    "train_data_prep = DataPrep(data_train)\n",
    "test_data_prep = DataPrep(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T04:40:28.628621Z",
     "start_time": "2021-03-26T04:40:28.517096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (60000, 28, 28, 1)\n",
      "Number of images in data: 60000\n",
      "max of data: 1.0 min of data: 0.0\n",
      "data type: <class 'numpy.ndarray'>\n",
      "data shape: (10000, 28, 28, 1)\n",
      "Number of images in data: 10000\n",
      "max of data: 1.0 min of data: 0.0\n",
      "data type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# prep the training data and test data\n",
    "data_train = train_data_prep.dataprep()\n",
    "data_test = test_data_prep.dataprep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T04:40:31.239556Z",
     "start_time": "2021-03-26T04:40:31.236173Z"
    }
   },
   "outputs": [],
   "source": [
    "class LabelsPrep:\n",
    "# class to prepare the labels as one-hot vectors\n",
    "    def __init__(self, data, num_classes):\n",
    "        self.labels = data\n",
    "        self.num_classes = num_classes\n",
    "     \n",
    "    \n",
    "    def labelsprep(self):\n",
    "        self.labels = tf.keras.utils.to_categorical(self.labels, num_classes = self.num_classes)\n",
    "        print('labels data shape:', self.labels.shape)\n",
    "        print('labels data type:', type(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T04:40:35.758288Z",
     "start_time": "2021-03-26T04:40:35.755886Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate instances from labelsprep class for training labels and test labels\n",
    "train_labels_prep = LabelsPrep(labels_train, 10)\n",
    "test_labels_prep = LabelsPrep(labels_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T04:40:37.547496Z",
     "start_time": "2021-03-26T04:40:37.541992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels data shape: (60000, 10)\n",
      "labels data type: <class 'numpy.ndarray'>\n",
      "labels data shape: (10000, 10)\n",
      "labels data type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# prep the training labels and test labels\n",
    "labels_train = train_labels_prep.labelsprep()\n",
    "labels_test = test_labels_prep.labelsprep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T04:40:41.033200Z",
     "start_time": "2021-03-26T04:40:41.028086Z"
    }
   },
   "outputs": [],
   "source": [
    "def CNN_dropout_hidden_fun(input_shape):    \n",
    "# define the CNN model\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape = input_shape))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Conv2D(256, kernel_size = (3,3),activation = tf.nn.relu))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Conv2D(128, kernel_size = (3,3),activation = tf.nn.relu))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "    model.add(Dense(100, activation = tf.nn.relu))\n",
    "    model.add(Dense(100,activation = tf.nn.relu))\n",
    "    model.add(Dense(10,activation = tf.nn.softmax))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T04:40:54.174078Z",
     "start_time": "2021-03-26T04:40:54.165902Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNN:\n",
    "# class to fit a CNN\n",
    "    def __init__(self, \n",
    "                 data_train, \n",
    "                 labels_train, \n",
    "                 data_test, \n",
    "                 labels_test, \n",
    "                 input_shape,\n",
    "                 parameters = {'loss':\"categorical_crossentropy\", \n",
    "                               'optimizer': \"adam\", \n",
    "                               'metrics': \"accuracy\", \n",
    "                               'epochs': 10, \n",
    "                               'batch_size': 1000, \n",
    "                               'shuffle': True}, \n",
    "                ):\n",
    "        self.data_train = data_train \n",
    "        self.labels_train = labels_train\n",
    "        self.data_test = data_test\n",
    "        self.labels_test = labels_test\n",
    "        self.params = parameters\n",
    "        self.input_shape = input_shape\n",
    "    \n",
    "    \n",
    "    def trainmodel(self):\n",
    "    # train and compile the model\n",
    "        self.CNN_dropout_hidden = CNN_dropout_hidden_fun(self.input_shape)\n",
    "        self.CNN_dropout_hidden.compile(loss = self.params['loss'], \n",
    "                                        optimizer = self.params['optimizer'], \n",
    "                                        metrics = self.params['metrics']\n",
    "                                       )\n",
    " \n",
    "\n",
    "    def accuracy(self):\n",
    "    # print accuracy history per epoch\n",
    "        self.history_dropout_hidden = self.CNN_dropout_hidden.fit(self.data_train, \n",
    "                                                                  self.labels_train, \n",
    "                                                                  validation_data = (self.data_test, self.labels_test), \n",
    "                                                                  epochs = self.params['epochs'],\n",
    "                                                                  batch_size = self.params['batch_size'],\n",
    "                                                                  shuffle = self.params['shuffle']\n",
    "                                                                 )\n",
    "        self.scores_dropout_hidden = self.CNN_dropout_hidden.evaluate(self.data_test,\n",
    "                                                                      self.labels_test\n",
    "                                                                     )    \n",
    "        print(\"Accuracy: %.2f%%\" %(self.scores_dropout_hidden[1]*100))\n",
    "   \n",
    "\n",
    "    def plottrain(self):\n",
    "    # plot loss and accuracy against epoch for training data\n",
    "        plt.subplot(121)\n",
    "        plt.plot(self.history_dropout_hidden.history['accuracy'])\n",
    "\n",
    "        plt.subplot(122)\n",
    "        plt.plot(self.history_dropout_hidden.history['loss'])\n",
    "    \n",
    "    \n",
    "    def plotval(self):\n",
    "    # plot loss and accuracy against epoch for validation data\n",
    "        plt.subplot(121)\n",
    "        plt.plot(self.history_dropout_hidden.history['val_accuracy'])\n",
    "\n",
    "        plt.subplot(122)\n",
    "        plt.plot(self.history_dropout_hidden.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T04:46:45.543408Z",
     "start_time": "2021-03-26T04:46:45.540594Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {'loss':\"categorical_crossentropy\", \n",
    "              'optimizer': \"adam\", \n",
    "              'metrics': \"accuracy\", \n",
    "              'epochs': 10, \n",
    "              'batch_size': 1000, \n",
    "              'shuffle': True\n",
    "             }\n",
    "input_shape = (28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T04:41:23.946954Z",
     "start_time": "2021-03-26T04:41:23.944638Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate an instance of class cnn\n",
    "cnn = CNN(data_train, \n",
    "          labels_train, \n",
    "          data_test, \n",
    "          labels_test, \n",
    "          input_shape, \n",
    "          parameters\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T04:41:26.072613Z",
     "start_time": "2021-03-26T04:41:25.942539Z"
    }
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "cnn.trainmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T04:41:28.797525Z",
     "start_time": "2021-03-26T04:41:28.540527Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: <class 'NoneType'>, <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e2c2d7066f15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# print accuracy history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-abe36ec9b669>\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m                                                                   \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                                                                   \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                                                                   \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'shuffle'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                                                                  )\n\u001b[1;32m     37\u001b[0m         self.scores_dropout_hidden = self.CNN_dropout_hidden.evaluate(self.data_test,\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1061\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m     self._adapter = adapter_cls(\n\u001b[1;32m   1106\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/venvs/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    969\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \"input: {}, {}\".format(\n\u001b[0;32m--> 971\u001b[0;31m             _type_name(x), _type_name(y)))\n\u001b[0m\u001b[1;32m    972\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'NoneType'>, <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "# print accuracy history \n",
    "cnn.accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy and loss against epoch\n",
    "cnn.plottrain()\n",
    "cnn.plottval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
